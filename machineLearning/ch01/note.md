# 统计学习方法概论

&emsp;&emsp;统计学习分为:

1. 监督学习

2. 非监督学习

3. 半监督学习

4. 强化学习

## 监督学习

**定义**:从给定的、有限的、用于学习的训练数据集合出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数集合，成为假设空间；应用某个评价准则，从假设空间中选取一个最优的模型，使它对已知训练数据及未知测试数据在给定的评价准则下有最优的预测；最优模型的选取由算法实现。

### 统计学习方法的三要素:模型，策略和算法

### 监督学习的任务是学习一个模型，使模型能够对任意给定的输入，对其相应的输出做出一个好的预测

### 策略

**监督学习的两个基本策略**:经验风险最小化和结构风险最小化

&emsp;&emsp;用损失函数来度量预测错误的程度。损失函数的期望,风险函数或期望损失:

&emsp;&emsp;$R_exp(f)=E_P[L(Y,f(X))]=\int_{x\times y}L(y,f(x))P(x,y)$

&emsp;&emsp;模型$f(x)$关于数据集的平均损失称为经验函数或经验风险:

&emsp;&emsp;$R_{emp}(f)=1/N\sum_{i=1}^{N}L(y_i,f(x_i))$


#### 经验风险最小化和结构风险最小化

&emsp;&emsp;经验风险最小化就是$minR_{emp}(f)=min 1/N\sum_{i=1}^{N}L(y_i,f(x_i))$

在数据量足够多的时候，经验风险最小化能保证有很好的学习效果，但是数据量少的时候，经验风险最小化容易出现“过拟合”现象。

**过拟合**:一味追求提高对训练数据的预测能力，所选模型的复杂度则往往会比模型更高。

&emsp;&emsp;结构风险最小化是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化。

&emsp;&emsp;$R_{srm}(f)=1/N\sum_{i=1}^{N}L(y_i,f(x_i))+A*J(f)$

&emsp;&emsp;J(f)为模型复杂度，模型越复杂，复杂度越大，惩罚值越大，反之越小。*A*大于0，结构风险小的模型往往对训练数据以及未知的测试数据有较好的预测。

&emsp;&emsp;结果风险最小化策略即:

&emsp;&emsp;$minR_{srm}(f)=min 1/N\sum_{i=1}^{N}L(y_i,f(x_i))+A*J(f)$

## 模型评估与模型选择

### 训练误差与测试误差

测试误差小的方法具有更好的预测能力，是更有效的方法。

### 过拟合与模型选择

&emsp;&emsp;在学习的过程中，要防止过拟合的出现，可以通过先确定模型的复杂度，再在给定的模型复杂度下，按照经验风险最小化的策略求解参数。

&emsp;&emsp;在学习过长中，测试误差随着模型复杂度的增加先减少，然后再增加；而训练误差则会一直减少，最后趋近与0.